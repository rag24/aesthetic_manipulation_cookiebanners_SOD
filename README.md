# Using Salient Object Detection to Identify Manipulative Cookie Banners that Circumvent GDPR
This repository includes the code used to collect the data, the collected dataset with button-level salience scores, and the code used to generate the salience scores.  This code and dataset corresponds with the "Using Salient Object Detection to Identify Manipulative Cookie Banners that Circumvent GDPR" paper published in ICWSM2026. 

The paper applies a unsupervised and generalizable slaient object detection model (SOD), called DeepRare [1], to the problem of aesthetic manipulation detection in cookie banners. To replicate the results and actually reproduce the pixel-level salience maps, instead of the provided element-level salience scores, you can download and run the DeepRare module from: https://github.com/numediart/VisualAttention-DeepRare2019.

Due to size, the image datasets that we collected from websites' landing pages are stored on Hugging Face. We provide a Shell Script in our repository to easily download the two datasets. After downloading Git Bash (https://git-scm.com/downloads) and Git LFS (https://git-lfs.github.com/), you can open Git Bash and navigate to the location where this repository is stored locally. Type "chmod +x download_datasets.sh" to make the script executable, and then "./download_datasets.sh" to download the two folders of images. There should be 2,490 images in the folder for websites visited from an EU IP address, and 2,492 images in the folder for websites visited from a NY IP address. 

For each image, we have manually labeled whether a cookie banner is present on the image. When a cookie banner is present, we have labeled its type (one of 17 types), the bounding box coordinates for the cookie banner and its buttons (e.g., accept, reject, settings), and whether the buttons are formatted as a link, hidden in the text, or placed in the corner away from other buttons. All of this manually labeled data is made available in the "data" folder. Each of the .csv files in the data folder is explained in deatil on the included Datasheet (also in folder). 


# Uses
1. Our Selenium crawler could be used to collect new images of website landing pages (and cookie banners for websites that implement them). We provide the Jupyter notebook file that does so (Data_Collection_Website_Landing_Page.ipynb).
2. We also provide the code to produce analysis on aesthetic manipulation detction for any newly collected datasets. However, many steps require manual labeling. After collecting new images, the "Aggregate_Salience_Scores_Bounding_Box.ipynb" file can be used to process the outputs of DeepRare (or any pixel-level salience map). The file walks through the steps of aggregating pixel-level salience scores into the more usable and interesting button/element-level salience scores. To apply to new data, this requires manually labeled bounding boxes to determine the locations of each element. The "Explaining_Button_Salience.ipynb" file shows how to explain the salience scores of each cookie banner button as a function of its characteristics (e.g., size, brightness, and location). To fully replicate paper analyses, manual labeling is required to determine the cookie banner design and whether each button is formatted as a link or hidden in the text. Finally, the "noise_robustness_sod_results.ipynb" describes how to inject random, barely perceptible noise into the input images to produce more robust pixel-level salience scores with DeepRare. 
3. This repository can be used to replicate the results of our paper "Using Salient Object Detection to Identify Manipulative Cookie Banners that Circumvent GDPR". In each of the three files: "Aggregate_Salience_Scores_Bounding_Box.ipynb", "Explaining_Button_Salience.ipynb", and "noise_robustness_sod_results.ipynb", there are two sections of the Jupyter notebook. The first section shows how to perform the analysis with new datasets, and the second shows how to replicate the results in our paper using the data we collected and processed (stored in the "data" folder). Each file states which of the data files should be used to replicate results. 
4. A computer-vision classifier could be trained to classify the collected and labeled website images that can be downloaded from Hugging Face. Classification tasks could include binary classification for whether a cookie banner exists in the image, and multi-class classification tasks to determine which of the 17 design types a given cookie banner displays. The labels for each image are stored in "data\image_labels.csv".
5. A computer-vision object detection model could be trained on our dataset to classify elements within a cookie banner. Our manually labeled dataset places bounding boxes around cookie banners, accept, reject, manage, and close buttons for over 1,600 website images. The manually labeled bounding box coordinates for each image can be found in "data/labeled_banners.csv".

[1] Kong, Phutphalla, et al. "DeepRare: generic unsupervised visual attention models." Electronics 11.11 (2022): 1696.
